# ğŸ“š Enrichisseur Bibliographique pour Obsidian


<!-- AUTO-GENERATED STATS - DO NOT EDIT -->
**Stats du projet** : 886 lignes | 23 fonctions | 2 classes
<!-- END AUTO-GENERATED -->

Agent Python pour enrichir automatiquement vos notes bibliographiques avec DOI et mÃ©tadonnÃ©es.

## ğŸ¯ FonctionnalitÃ©s (Ã‰tape 1)

- âœ… Scanne les fichiers Markdown pour tags `#reflitterature`
- âœ… Extrait le contexte autour des rÃ©fÃ©rences
- âœ… Cherche des rÃ©fÃ©rences complÃ¨tes dans votre fichier bibliographie
- âœ… Utilise un LLM local (Ollama) pour nettoyer les erreurs OCR
- âœ… Interroge les APIs gratuites (OpenAlex prioritaire, CrossRef en backup)
- âœ… GÃ©nÃ¨re un rapport avec scores de confiance (JSON + Markdown)

## ğŸ“‹ PrÃ©requis

1. **Python 3.8+** (vÃ©rifier : `python3 --version`)
2. **Ollama** installÃ© et lancÃ© localement
3. **Git** (optionnel, pour cloner)

## ğŸš€ Installation

### 1. Copier les fichiers dans votre vault Obsidian

Copiez le dossier `biblio-enricher/` Ã  la racine de votre vault :

```
MonVault/
â”œâ”€â”€ biblio-enricher/     â† Coller ici
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ 1.2 The impact...md
â”œâ”€â”€ 4.4 Bibliographic references.md
â””â”€â”€ ...
```

### 2. Installer les dÃ©pendances Python

Ouvrez un terminal dans le dossier `biblio-enricher/` :

```bash
cd /chemin/vers/MonVault/biblio-enricher

# CrÃ©er un environnement virtuel (recommandÃ©)
python3 -m venv venv

# Activer l'environnement
# Sur Linux/Mac :
source venv/bin/activate
# Sur Windows :
venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 3. Installer et configurer Ollama

**Installation d'Ollama** :
- Linux/Mac : https://ollama.com/download
- VÃ©rifier : `ollama --version`

**TÃ©lÃ©charger le modÃ¨le** :
```bash
ollama pull llama3.1
```

**DÃ©marrer Ollama** :
```bash
ollama serve
```
(Laissez cette fenÃªtre de terminal ouverte)

### 4. Configuration (optionnel)

Ã‰ditez `config.py` pour ajuster :

```python
# Chemins
VAULT_PATH = "."  # Dossier de votre vault
BIBLIO_FILE = "4.4 Bibliographic references.md"

# ModÃ¨le LLM
OLLAMA_MODEL = "llama3.1"  # Ou un autre modÃ¨le installÃ©

# APIs (optionnel mais recommandÃ©)
OPENALEX_EMAIL = "votre.email@exemple.com"  # Pour Ãªtre poli avec l'API
CROSSREF_EMAIL = "votre.email@exemple.com"
```

**Note** : Les APIs OpenAlex et CrossRef sont **gratuites** et **ne nÃ©cessitent pas de clÃ©**. Fournir votre email est optionnel mais recommandÃ© (meilleurs quotas).

## ğŸ® Utilisation

### Commande de base

```bash
python agent.py "nom_du_fichier.md"
```

### Exemples

```bash
# Traiter un fichier spÃ©cifique
python agent.py "1.2 The impact of digitalisation on intellectual life.md"

# Si le nom contient des espaces, utilisez des guillemets !
python agent.py "2.3 The world of open materials.md"

# Sans extension .md (ajoutÃ©e automatiquement)
python agent.py "1.2 The impact of digitalisation on intellectual life"
```

### Sortie

Le script gÃ©nÃ¨re deux fichiers dans `results/` :

1. **JSON** : `nom_fichier_YYYYMMDD_HHMMSS.json`
   - Format structurÃ© pour traitement ultÃ©rieur
   - Contient toutes les mÃ©tadonnÃ©es

2. **Markdown** : `nom_fichier_YYYYMMDD_HHMMSS_report.md`
   - Rapport lisible par humain
   - Visualisable directement dans Obsidian

## ğŸ“Š Exemple de sortie

```markdown
## RÃ©fÃ©rence 1

**Ligne 18**: deux rÃ©fÃ©rences Habermas, sphÃ¨re publique

**MÃ©tadonnÃ©es extraites**:
- Auteur: Habermas, JÃ¼rgen
- Titre: The Structural Transformation of the Public Sphere
- AnnÃ©e: 1992

**RÃ©sultat API (OpenAlex)**:
- DOI: `10.1080/01916599.2024.2365143`
- URL: https://doi.org/10.1080/01916599.2024.2365143
- Score de confiance: 87.5%
```

## ğŸ”§ DÃ©pannage

### "Ollama n'est pas accessible"
```bash
# VÃ©rifier qu'Ollama tourne
ollama list

# Si non, le dÃ©marrer
ollama serve
```

### "Le modÃ¨le llama3.1 n'est pas installÃ©"
```bash
ollama pull llama3.1
```

### "Fichier non trouvÃ©"
- VÃ©rifiez que vous Ãªtes dans le bon dossier (`cd biblio-enricher`)
- VÃ©rifiez le chemin dans `config.py` â†’ `VAULT_PATH`
- Utilisez des guillemets autour du nom de fichier

### "Aucune rÃ©fÃ©rence trouvÃ©e"
- VÃ©rifiez que vos tags sont au format : `%% #reflitterature description %%`
- Pas d'espace manquant avant/aprÃ¨s `%%`

## ğŸ“ Structure des fichiers

```
biblio-enricher/
â”œâ”€â”€ agent.py              # Script principal (lancez celui-ci)
â”œâ”€â”€ config.py             # Configuration (modifiez selon vos besoins)
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ README.md            # Ce fichier
â””â”€â”€ results/             # Dossier de sortie (crÃ©Ã© automatiquement)
    â”œâ”€â”€ fichier_20250101_120000.json
    â””â”€â”€ fichier_20250101_120000_report.md
```

## ğŸšš PortabilitÃ© entre vaults

Pour copier ce systÃ¨me vers un autre vault :

1. **Copier le dossier** `biblio-enricher/` complet
2. **Ajuster** `config.py` si nÃ©cessaire (notamment `BIBLIO_FILE`)
3. **RÃ©activer** l'environnement virtuel :
   ```bash
   cd biblio-enricher
   source venv/bin/activate  # ou venv\Scripts\activate sur Windows
   ```

C'est tout ! Les dÃ©pendances sont dÃ©jÃ  installÃ©es dans `venv/`.

## ğŸ”® Ã‰volutions futures (Ã‰tapes 2-7)

- [ ] Interface interactive pour valider/corriger les rÃ©sultats
- [ ] Ajout automatique Ã  Zotero via API
- [ ] Support d'ISBN pour les livres
- [ ] Traitement par lot de plusieurs fichiers
- [ ] Cache local pour Ã©viter requÃªtes API redondantes
- [ ] Export vers BibTeX/CSL-JSON

## ğŸ“ Notes

- **ConfidentialitÃ©** : Toutes les APIs utilisÃ©es sont publiques et gratuites
- **LLM local** : Vos notes ne quittent jamais votre machine (Ollama est local)
- **Pas de modification** : Le script ne modifie JAMAIS vos fichiers .md originaux
- **Format des tags** : Seuls les tags `%% #reflitterature ... %%` sont traitÃ©s

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifiez la section "DÃ©pannage" ci-dessus
2. VÃ©rifiez que tous les prÃ©requis sont installÃ©s
3. Consultez les logs d'erreur dans le terminal

## ğŸ“œ Licence

Libre d'utilisation pour vos travaux acadÃ©miques en humanitÃ©s digitales.