# ğŸš€ DÃ©marrage rapide

## ğŸ“¦ Installation (5 minutes)

### 1. Installer Ollama

**Linux** :
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Mac** :
TÃ©lÃ©chargez depuis https://ollama.com/download

**VÃ©rifier** :
```bash
ollama --version
```

### 2. TÃ©lÃ©charger le modÃ¨le LLM

```bash
ollama pull llama3.1
```
(Cela prend quelques minutes, ~4 GB)

### 3. DÃ©marrer Ollama

```bash
ollama serve
```
Laissez cette fenÃªtre de terminal ouverte en arriÃ¨re-plan.

### 4. Installer les dÃ©pendances Python

Dans un **nouveau terminal** :

```bash
cd /chemin/vers/votre/vault/biblio-enricher

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## â–¶ï¸ PremiÃ¨re utilisation

### Test rapide

```bash
python agent.py "1.2 The impact of digitalisation on intellectual life.md"
```

Vous devriez voir :
```
============================================================
ğŸ“š ENRICHISSEUR BIBLIOGRAPHIQUE POUR OBSIDIAN
============================================================
ğŸ“– Scan du fichier: 1.2 The impact...md
   âœ“ 4 rÃ©fÃ©rence(s) #reflitterature trouvÃ©e(s)

ğŸ” Traitement de 4 rÃ©fÃ©rence(s)...
...
âœ… TRAITEMENT TERMINÃ‰
```

### Consulter les rÃ©sultats

Ouvrez le fichier gÃ©nÃ©rÃ© dans `results/` :
- `*_report.md` â†’ Lisible dans Obsidian
- `*.json` â†’ Pour traitement automatisÃ©

## ğŸ“§ Configuration des APIs (optionnel)

Les APIs OpenAlex et CrossRef sont **gratuites et sans clÃ©**.

Pour amÃ©liorer les quotas, ajoutez votre email dans `config.py` :

```python
OPENALEX_EMAIL = "votre.email@exemple.com"
CROSSREF_EMAIL = "votre.email@exemple.com"
```

**Aucune inscription requise !** Les APIs sont totalement ouvertes.

## ğŸ¯ Utilisation quotidienne

1. **DÃ©marrer Ollama** (si pas dÃ©jÃ  lancÃ©) :
   ```bash
   ollama serve
   ```

2. **Lancer l'enrichissement** :
   ```bash
   python agent.py "votre_fichier.md"
   ```

3. **Consulter** `results/` dans Obsidian

## ğŸ”„ Copier vers un autre vault

1. Copiez le dossier `biblio-enricher/` complet
2. Ajustez `config.py` â†’ `BIBLIO_FILE` si nÃ©cessaire
3. C'est tout ! (les dÃ©pendances sont dÃ©jÃ  installÃ©es)

## â“ ProblÃ¨mes courants

### "Ollama not found"
â†’ Assurez-vous qu'Ollama tourne : `ollama serve`

### "Model not found"
â†’ TÃ©lÃ©chargez le modÃ¨le : `ollama pull llama3.1`

### "No module named 'requests'"
â†’ Installez les dÃ©pendances : `pip install -r requirements.txt`

### Aucune rÃ©fÃ©rence trouvÃ©e
â†’ VÃ©rifiez le format : `%% #reflitterature description %%`

## ğŸ“š Exemple de workflow

```bash
# 1. DÃ©marrer Ollama (une fois au dÃ©but de votre session)
ollama serve &

# 2. Traiter plusieurs fichiers
python agent.py "1.2 The impact of digitalisation.md"
python agent.py "2.3 The world of open materials.md"

# 3. Consulter tous les rapports dans results/
ls results/*.md
```

## ğŸ“ Prochaines Ã©tapes

Une fois familiarisÃ© avec l'Ã‰tape 1 :
- Ã‰tape 2 : Validation interactive des rÃ©sultats
- Ã‰tape 3 : IntÃ©gration avec Zotero
- Ã‰tape 4 : Traitement par lots

---

**Besoin d'aide ?** Consultez le README.md complet pour plus de dÃ©tails.
